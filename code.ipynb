{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993f402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:32.684815Z",
     "start_time": "2025-05-15T06:35:32.675487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all necessary libraries \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98e737",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:38.316232Z",
     "start_time": "2025-05-15T06:35:34.977620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"./dataset.csv\")\n",
    "data = data.astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf2207",
   "metadata": {},
   "source": [
    "### Data types exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088edb50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:42.314554Z",
     "start_time": "2025-05-15T06:35:42.291887Z"
    }
   },
   "outputs": [],
   "source": [
    "data_types = data.dtypes\n",
    "data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c7b63",
   "metadata": {},
   "source": [
    "# Data preprocessing and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db542f37",
   "metadata": {},
   "source": [
    "### Dublicates. Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26419e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:46.827694Z",
     "start_time": "2025-05-15T06:35:45.930712Z"
    }
   },
   "outputs": [],
   "source": [
    "#check data's integrity\n",
    "data.duplicated()\n",
    "int(data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14babf2",
   "metadata": {},
   "source": [
    "This are a lot of duplicates but I assume that this happens verry quick, even if it is really a different patient, with such a huge amount of categorical 2 group variables. Because of this it would be bad to drop dublicates and keep respectively the first of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faa477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:50.268340Z",
     "start_time": "2025-05-15T06:35:50.009191Z"
    }
   },
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "data.isna().sum(axis=1)\n",
    "data.isna().any(axis=1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d584f0c",
   "metadata": {},
   "source": [
    "<- no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e652b8",
   "metadata": {},
   "source": [
    "Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de4ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:52.614080Z",
     "start_time": "2025-05-15T06:35:52.574197Z"
    }
   },
   "outputs": [],
   "source": [
    "X=data.drop(['Diabetes_012'], axis=1)\n",
    "y=data['Diabetes_012']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686333e",
   "metadata": {},
   "source": [
    "Compute correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ee8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:35:56.742306Z",
     "start_time": "2025-05-15T06:35:55.345835Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = X.corr().abs() #abs trat negative values same as positive\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0974c21",
   "metadata": {},
   "source": [
    "Plot correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199d740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.155322600Z",
     "start_time": "2025-05-14T14:29:20.170771Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ae382",
   "metadata": {},
   "source": [
    "Remove higly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbe583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.155322600Z",
     "start_time": "2025-05-14T14:29:22.340127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation > 0.9 (threshold is adjustable)\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "# Drop redundant features\n",
    "X_reduced = X.drop(columns=to_drop)\n",
    "print(f\"Removed {len(to_drop)} highly correlated features: {to_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaab549",
   "metadata": {},
   "source": [
    "Use mutual information filter methods to quantify the amount of information that one variable provides about another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378809ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.155322600Z",
     "start_time": "2025-05-14T14:29:22.928204Z"
    }
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f8c37",
   "metadata": {},
   "source": [
    "Let's try backword stepwise elimination (with multinominal logistische regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19cab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.157842400Z",
     "start_time": "2025-05-14T13:18:48.184347Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Add constant for intercept\n",
    "def multinomial(X): \n",
    "    X = sm.add_constant(X)\n",
    "    cols = list(X.columns)\n",
    "    pmax = 1\n",
    "\n",
    "    while len(cols) > 0:\n",
    "        # Inside your while loop:\n",
    "        model = sm.MNLogit(y, X[cols]).fit(disp=0)\n",
    "\n",
    "        # Take max p-value per feature across classes\n",
    "        p_values = model.pvalues\n",
    "        p_values_max = p_values.max(axis=1)\n",
    "        pmax = p_values_max.max()\n",
    "        feature_with_p_max = p_values_max.idxmax()\n",
    "\n",
    "        # Backward elimination step\n",
    "        if pmax > 0.05:\n",
    "            print(f\"Dropping '{feature_with_p_max}' with p = {pmax:.4f}\")\n",
    "            cols.remove(feature_with_p_max)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Selected features: {cols}\")\n",
    "    return cols\n",
    "\n",
    "X_BSE_list = multinomial(X)\n",
    "X_BSE_list.remove('const')\n",
    "X_postBSE = X[X_BSE_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb1ac8",
   "metadata": {},
   "source": [
    "LABEL, CATEGORICAL AND NUMERICAL FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f413d10e",
   "metadata": {},
   "source": [
    "**Numerical (Interval data** <- has no meaningful zero **) :** \n",
    "BMI\n",
    "\n",
    "**Categorical (Ordinal data) :**\n",
    "Diabetes_012, Age, GenHlth, MentHlth, PhyaHlth, Education, Income) \n",
    "\n",
    "**Categorical (Nominal data) :** Rest \n",
    "-> (HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f3c2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.157842400Z",
     "start_time": "2025-05-14T13:18:44.303742Z"
    }
   },
   "outputs": [],
   "source": [
    "label = ['Diabetes_012']\n",
    "num_cols = ['BMI', 'Age']\n",
    "cate_cols = data.columns.drop(['BMI', 'Age', 'Diabetes_012'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50a543",
   "metadata": {},
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f4281",
   "metadata": {},
   "source": [
    "Distribution label Diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd04b41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.157842400Z",
     "start_time": "2025-05-13T19:03:03.446318Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.countplot(data=data, x='Diabetes_012')\n",
    "plt.title('Distribution of Diabetes_012')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4066c",
   "metadata": {},
   "source": [
    "For the numerical features. See if there is a difference between Diabetes_012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b79aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.159587Z",
     "start_time": "2025-05-13T19:03:05.388716Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(num_cols)):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=data, x='Diabetes_012', y=num_cols[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a92b9d",
   "metadata": {},
   "source": [
    "Many outliers in BMI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c60df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.159587Z",
     "start_time": "2025-05-13T19:03:08.458642Z"
    }
   },
   "outputs": [],
   "source": [
    "#Suggestion from Noemi:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc232b",
   "metadata": {},
   "source": [
    "➡ **Box Plot:** Use a box plot to show the data distribution and identify **outliers**. This type of chart works well when you have a lot of data and want to see the range and median of the data. A box-and-whisker plot displays the summary of a set of data:  the minimum, first quartile, median, third quartile, and maximum of the data subset. \n",
    "\n",
    "➡**Violin plots**: Use a box plot to visualize distribution and probability.  This hybrid chart works  version to shows the full distribution of the data and the peaks in the numeric dataset.  \n",
    "\n",
    "➡ **Bar Chart:** Use a bar chart to compare categories or groups. This chart type works well when the data is discrete and not continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb425b",
   "metadata": {},
   "source": [
    "Look at the distribution of every categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5901453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.159587Z",
     "start_time": "2025-05-13T19:03:08.684785Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in cate_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=data, x=col, hue='Diabetes_012')\n",
    "    plt.title(f'{col} vs Diabetes')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ffd20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.161599700Z",
     "start_time": "2025-05-13T19:03:43.474605Z"
    }
   },
   "outputs": [],
   "source": [
    "#for age as a categorical variable\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=data, x='Age', hue='Diabetes_012')\n",
    "plt.title('Age Groups vs Diabetes')\n",
    "plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f7574",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709c61c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ef0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, make_scorer, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7651d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset.csv\")\n",
    "X=data.drop(['Diabetes_012'], axis=1)\n",
    "y=data['Diabetes_012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919cc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# === Set up scaling only for ordinal/continuous columns ===\n",
    "ordinal_col = ['GenHlth', 'PhysHlth', 'MentHlth','Education', 'Income', 'BMI', 'Age']\n",
    "binary_col = [col for col in X.columns if col not in ordinal_col]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scale_ordial', StandardScaler(), ordinal_col), \n",
    "    ('pass_binaries', 'passthrough', binary_col) # binary left untouched\n",
    "    ])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c48b99",
   "metadata": {},
   "source": [
    "Feature Selection I (SelectKBest, f_classif, with k tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebb58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kbest = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('select', SelectKBest(score_func=f_classif)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'select__k': list(range(1, 22))  # Try all k values from 1 to 21\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline_kbest,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',  # Or 'recall_macro', etc.\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "results_df = pd.DataFrame(grid.cv_results_)[['param_select__k', 'mean_test_score', 'mean_train_score']]\n",
    "results_df.columns = ['k', 'Test Score (F1)', 'Train Score (F1)']\n",
    "results_df.sort_values('Test Score (F1)', ascending=False, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d742dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('select', SelectKBest(score_func=f_classif, k=17)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline1.fit(X_train, y_train)\n",
    "y_pred = pipeline1.predict(X_test)\n",
    "f1_kbest = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"F1 Score:  {f1_kbest:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e348f3e",
   "metadata": {},
   "source": [
    "Feature Selection II (backwards stepwise elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'Sex', 'Age', 'Education', 'Income'] #X_BSE_list\n",
    "ordinal_cols_reduced = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "binary_cols_reduced = [col for col in selected_features if col not in ordinal_cols_reduced]\n",
    "X_train_reduced = X_train[selected_features]\n",
    "X_test_reduced = X_test[selected_features]\n",
    "\n",
    "preprocessor2 = ColumnTransformer(transformers=[\n",
    "    ('scale_ordinals', StandardScaler(), ordinal_cols_reduced),\n",
    "    ('pass_binaries', 'passthrough', binary_cols_reduced)\n",
    "])\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessing', preprocessor2), \n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train_reduced, y_train)\n",
    "\n",
    "y_pred = pipeline2.predict(X_test_reduced)\n",
    "f1_BSE = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"F1 Score:  {f1_BSE:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b3e94",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca84a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === try saga with elasticnet ===\n",
    "param_grid = {\n",
    "    'clf__penalty': ['elasticnet'],\n",
    "    'clf__solver': ['saga'],  # Must match penalty type\n",
    "    'clf__max_iter': [5000],\n",
    "    'clf__l1_ratio': [0.1,0.5,0.9]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid,\n",
    "    scoring='f1_macro', \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best F1 score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === try saga with other penalties ===\n",
    "param_grid = {\n",
    "    'clf__penalty': ['l1','l2',None],\n",
    "    'clf__solver': ['saga'],  # Must match penalty type\n",
    "    'clf__max_iter': [5000],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid,\n",
    "    scoring='f1_macro', \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best F1 score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === try lbfgs with different C ===\n",
    "param_grid = {\n",
    "    'clf__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l2', None],\n",
    "    'clf__solver': ['lbfgs'],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid,\n",
    "    scoring='f1_macro', \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best F1 score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2fc8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79     42741\n",
      "           1       0.03      0.28      0.06       926\n",
      "           2       0.35      0.59      0.44      7069\n",
      "\n",
      "    accuracy                           0.66     50736\n",
      "   macro avg       0.44      0.52      0.43     50736\n",
      "weighted avg       0.85      0.66      0.73     50736\n",
      "\n",
      "\n",
      " === Logistic Regression Evaluation: ===\n",
      "Accuracy:  0.6609\n",
      "Precision: 0.4441\n",
      "Recall:    0.5166\n",
      "F1 Score:  0.4305\n",
      "\n",
      " === Confusion Matrix: ===\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_final = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('select', SelectKBest(score_func=f_classif, k=17)),\n",
    "    ('clf', LogisticRegression(C=0.0001, solver='lbfgs', class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_final.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_final.predict(X_test)\n",
    "f1_BSE = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\n === Logistic Regression Evaluation: ===\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === 7. Confusion Matrix ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_final.classes_)\n",
    "\n",
    "print(\"\\n === Confusion Matrix: ===\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for LR')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81443b76",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06518b85",
   "metadata": {},
   "source": [
    "### Assumptions we make while using Decision tree\n",
    "\n",
    "- At the beginning, we consider the whole training set as the root.\n",
    "- Attributes are assumed to be categorical for information gain and for gini index, attributes are assumed to be continuous.\n",
    "- On the basis of attribute values records are distributed recursively.\n",
    "- We use statistical methods for ordering attributes as root or internal node.\n",
    "\n",
    "https://www.geeksforgeeks.org/decision-tree-implementation-python/\n",
    "\n",
    "#### Pseudocode \n",
    "\n",
    "1. Find the best attribute and place it on the root node of the tree.\n",
    "2. Now, split the training set of the dataset into subsets. While making the subset make sure that each subset of training dataset should have the same value for an attribute.\n",
    "3. Find leaf nodes in all branches by repeating 1 and 2 on each subset.\n",
    "\n",
    "#### Decision Trees doesn't need to me standartised.\n",
    "\n",
    "Decision Trees (and related models like Random Forests and Gradient Boosted Trees) are not affected by feature scaling. Here's why:\n",
    "\n",
    "Trees split data based on feature thresholds, not distances or magnitudes.\n",
    "For example, a decision tree might split on \"Feature X > 5\" — it doesn't care whether Feature X is in the range [0,1] or [0, 1000].\n",
    "\n",
    "##### When you do need standardization:\n",
    "Standardization (using StandardScaler() or MinMaxScaler()) is important for algorithms that are distance-based or gradient-based, such as:\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression\n",
    "- Linear Regression\n",
    "- Neural Networks\n",
    "\n",
    "These models are sensitive to feature scale and can perform poorly if features are not standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79abdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X hole data Frame\n",
    "# y hale data Frame\n",
    "\"\"\"\n",
    "# === 2. Train/test split === - Janet\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Split training/test - Oliver\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rdf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ==== Train/test split ==== - Noah Light\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_model, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ==== 2. TRAIN/TEST SPLIT ==== - Noah neuronal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\"\"\"\n",
    "# Function to split the dataset into features and target variables\n",
    "\n",
    "def splitdataset(X, y):\n",
    "\n",
    "    # Splitting the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \"\"\" How they did in on geeksforgeeks.org:\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \n",
    "          X, Y, test_size = 0.3, random_state = 100)\n",
    "    \"\"\"\n",
    "\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def Evaluation(y_test, y_pred, y_pred_proba=None):\n",
    "    \n",
    "    print(\"Accuracy:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", sklearn.metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", sklearn.metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1 Score:\", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "    if(y_pred_proba):\n",
    "        print(\"Log Loss:\", sklearn.metrics.log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "    print(\"Cohen Kappa Score:\", sklearn.metrics.cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "    # Classification report per classe\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing first on the hole data set and again with feature selection\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "#DataSetSplit_Reduced = splitdataset(X_reducedRelevant,y)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = dtree.predict(X_test)\n",
    "Accurat = accuracy_score(y_test, y_predicted)\n",
    "F1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "print(f\"accuracy: {Accurat}\")\n",
    "print(f\"F1: {F1}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitdataset(X_postBSE,y)\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=5)\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = dtree.predict(X_test)\n",
    "Accurat = accuracy_score(y_test, y_predicted)\n",
    "F1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "print(f\"accuracy: {Accurat}\")\n",
    "print(f\"F1: {F1}\")\n",
    "\n",
    "Evaluation(y_test, y_predicted)\n",
    "\"\"\" ploting desicion tree\n",
    "plt.figure(figsize=(40, 10))\n",
    "sklearn.tree.plot_tree(dtree, feature_names=newList)\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261c07c",
   "metadata": {},
   "source": [
    "with backword stepwise elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = splitdataset(X_postBSE,y)\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=5)\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = dtree.predict(X_test)\n",
    "Accurat = accuracy_score(y_test, y_predicted)\n",
    "F1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "print(f\"accuracy: {Accurat}\")\n",
    "print(f\"F1: {F1}\")\n",
    "\n",
    "Evaluation(y_test, y_predicted)\n",
    "\"\"\" ploting desicion tree\n",
    "plt.figure(figsize=(40, 10))\n",
    "sklearn.tree.plot_tree(dtree, feature_names=newList)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53013aa",
   "metadata": {},
   "source": [
    "Trying diffrent settings in the DecisionTreeClassifier() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Variating_DecisionTreeClassifier(X_train, y_train, X_test):\n",
    "    class_weight = [\"balanced\",None]\n",
    "    criterions = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    maxDepth = [2,4,8,16,32,None]\n",
    "\n",
    "    maxf1 = 0\n",
    "    parameters = \"\"\n",
    "\n",
    "    for criterion in criterions:\n",
    "        for d in maxDepth:\n",
    "            for cl in class_weight:\n",
    "            \n",
    "                #print(\"========= Class weigth:\" + str(cl) + \" Method: \" + criterion + \", maxDepth: \" + str(d) + \" ========\")\n",
    "                dtree = DecisionTreeClassifier(criterion=criterion, max_depth=d, class_weight=cl)\n",
    "                dtree.fit(X_train, y_train)\n",
    "                y_predicted = dtree.predict(X_test)\n",
    "                if(sklearn.metrics.f1_score(y_test, y_predicted, average='macro') > maxf1):\n",
    "                    maxf1 = sklearn.metrics.f1_score(y_test, y_predicted, average='macro')\n",
    "                    parameters = \"Criterion:\" + criterion + \" , depth: \" + str(d) + \", class_weight:\" + str(cl)\n",
    "                #print(\"F1 Score:\", sklearn.metrics.f1_score(y_test, y_predicted, average='macro'))\n",
    "\n",
    "    print(\"Best result: \" + str(maxf1) + \" with parameter \" + parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c0e04",
   "metadata": {},
   "source": [
    "Using SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c06f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split hole data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X, y)\n",
    "\n",
    "Variating_DecisionTreeClassifier(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c08741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nececcary for same outputs as others?:\n",
    "\n",
    "#from Oliver:\n",
    "\n",
    "# Train a Random Forest to get feature importances\n",
    "# he uses class_weight='balanced'\n",
    "temp_rdf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "temp_rdf.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "y_pred = rdf.predict(X_test)\n",
    "y_pred_proba = rdf.predict_proba(X_test)\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91baed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#training a decision tree classifier using the Gini index as the splitting criterion\n",
    "def train_using_gini(X_train, X_test, y_train):\n",
    "\n",
    "    # Creating the classifier object\n",
    "    clf_gini = DecisionTreeClassifier(criterion=\"gini\",\n",
    "                                      random_state=42, max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "    # Performing training\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    return clf_gini\n",
    "\n",
    "\n",
    "def train_using_entropy(X_train, X_test, y_train):\n",
    "\n",
    "    # Decision tree with entropy\n",
    "    clf_entropy = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\", random_state=42,\n",
    "        max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "    # Performing training\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    return clf_entropy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e260f98",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.163612700Z",
     "start_time": "2025-05-13T19:03:45.905134Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             log_loss, cohen_kappa_score, classification_report, confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Select the features\n",
    "rdf_selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "rdf_selector.fit(X_scaled, y)\n",
    "X_rdf= rdf_selector.transform(X_scaled)\n",
    "selected_features = X.columns[rdf_selector.get_support()]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Create a dataframe with the selected features\n",
    "X_selected_rdf = pd.DataFrame(X_rdf, columns=selected_features, index=data.index)\n",
    "\n",
    "# RANDOM FOREST\n",
    "rdf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Split training/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rdf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Fit the model\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = rdf.predict(X_test)\n",
    "y_pred_proba = rdf.predict_proba(X_test)\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bae92",
   "metadata": {},
   "source": [
    "Random forest feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest to get feature importances\n",
    "temp_rdf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "temp_rdf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = temp_rdf.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top k important features\n",
    "k=6\n",
    "top_features = importance_df['Feature'].head(k).values\n",
    "print(\"Top Random Forest Features:\", top_features)\n",
    "\n",
    "# Use only the selected features\n",
    "X_selected_rf = pd.DataFrame(X, columns=X.columns)[top_features]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train final model\n",
    "rdf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rdf.predict(X_test)\n",
    "y_pred_proba = rdf.predict_proba(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57225d6",
   "metadata": {},
   "source": [
    "HPT after FS RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#==== Train-test split ====\n",
    "# Split training/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, class_weight='balanced', random_state=42)\n",
    "\n",
    "# ==== Parametri per RandomizedSearch ====\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.5],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': ['balanced', {0:1, 1:10, 2:5}, {0:1, 1:15, 2:10}]\n",
    "}\n",
    "\n",
    "# ==== RandomizedSearch ====\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==== Fit ====\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ==== Best Model ====\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# ==== Confusion Matrix ====\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# ==== Metrics ====\n",
    "print(\"Best parameters from tuning:\", random_search.best_params_)\n",
    "print(\"Best CV score:\", random_search.best_score_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088b69e",
   "metadata": {},
   "source": [
    "HPT for random forest I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "df_selector = SelectKBest(score_func=f_classif,k=9)\n",
    "rdf_selector.fit(X_scaled, y)\n",
    "X_rdf= rdf_selector.transform(X_scaled)\n",
    "selected_features = X.columns[rdf_selector.get_support()]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Create a dataframe with the selected features\n",
    "X_selected_rdf = pd.DataFrame(X_rdf, columns=selected_features, index=data.index)\n",
    "\"\"\"\n",
    "\n",
    "# Split training/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, class_weight='balanced', random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', 0.5, 0.8, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random search\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',  # puoi cambiare qui\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 score:\", random_search.best_score_)\n",
    "\n",
    "\"\"\"\n",
    "# Miglior modello\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(\"Best parameters from tuning:\", random_search.best_params_)\n",
    "print(\"Accuracy:\", best_rf.score(X_test, y_test))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#  ==== Scaling ====\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ==== Feature selection ====\n",
    "selector = SelectKBest(score_func=f_classif, k=9)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "X_selected_df = pd.DataFrame(X_selected, columns=selected_features, index=data.index)\n",
    "\"\"\"\n",
    "# ==== Train-test split ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# ==== Pipeline ====\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ==== Parametri per RandomizedSearch ====\n",
    "param_dist = {\n",
    "    'rf__n_estimators': [50, 100, 150, 200],\n",
    "    'rf__max_depth': [5, 10, 15, 20, None],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2', 0.5],\n",
    "    'rf__bootstrap': [True, False],\n",
    "    'rf__class_weight': ['balanced', {0:1, 1:10, 2:5}, {0:1, 1:15, 2:10}]\n",
    "}\n",
    "\n",
    "# ==== RandomizedSearch ====\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==== Fit ====\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 score:\", random_search.best_score_)\n",
    "\n",
    "\"\"\"\n",
    "# ==== Best Model ====\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# ==== Confusion Matrix ====\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# ==== Metrics ====\n",
    "print(\"Best parameters from tuning:\", random_search.best_params_)\n",
    "print(\"Best CV score:\", random_search.best_score_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c12d3",
   "metadata": {},
   "source": [
    "SMOTE + RF. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline con SMOTE + Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit della pipeline sul training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sul test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (SMOTE + Random Forest)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Classifier with SMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "# Classification report per classe\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf63a83",
   "metadata": {},
   "source": [
    "Let's try an undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Pipeline con Undersampling + Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('undersample', RandomUnderSampler(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit della pipeline sul training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sul test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Undersampling + Random Forest)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Classifier with Random Undersampling\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "# Classification report per classe\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63556d03",
   "metadata": {},
   "source": [
    "BalancedBaggingClassifier. I'm trying to find a better classifier for very unbalanced dataset. This one uses trained undersample. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf49eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# Balanced Bagging with Random Forest as base estimator\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    sampling_strategy='auto',  # Bilancia automaticamente le classi\n",
    "    replacement=False,\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit del modello\n",
    "bbc.fit(X_train, y_train)\n",
    "\n",
    "# Predizione\n",
    "y_pred = bbc.predict(X_test)\n",
    "y_pred_proba = bbc.predict_proba(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (BalancedBaggingClassifier)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Valutazione\n",
    "print(\"BalancedBaggingClassifier with RandomForest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70e39e",
   "metadata": {},
   "source": [
    "XGBoost. Also good for very unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b089ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calcolo pesi delle classi per XGBoost\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "# Inizializza XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=1  # Ignorato in multiclass, usiamo sample_weight\n",
    ")\n",
    "\n",
    "# Fit con sample_weight\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title('Confusion Matrix (XGBoost)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc89ce",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3a5f2e6107a64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.165625200Z",
     "start_time": "2025-05-09T08:29:52.374075Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y.value_counts(normalize=True)) ##High imbalance --> Oversampling \n",
    "#Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.pie(data['Diabetes_012'].value_counts(), labels=data['Diabetes_012'].value_counts().index,autopct='%1.1f%%' , startangle=140)\n",
    "plt.title('Distribution of the labels')\n",
    "plt.legend(title='Diabetes_012')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.savefig('pie_chart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe784f22d9bcac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:34:10.166132600Z",
     "start_time": "2025-05-13T09:02:09.996504Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    log_loss, cohen_kappa_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "# ==== Preprocessing ====\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# ==== Selezione delle migliori features ====\n",
    "selected_cols = multinomial(X_scaled_df)\n",
    "if 'const' in selected_cols:\n",
    "    selected_cols.remove('const')\n",
    "X_model = X_scaled_df[selected_cols]\n",
    "\n",
    "# ==== Train/test split ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_model, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ==== Oversampling SMOTE ====\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ==== Calcolo class_weight ====\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_bal), y=y_train_bal)\n",
    "class_weight_dict = dict(zip(np.unique(y_train_bal), class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# ==== Modello LightGBM ====\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(\n",
    "    X_train_bal, y_train_bal,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "# ==== Predizioni ====\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_probs = model.predict_proba(X_test)\n",
    "\n",
    "# ==== Valutazione ====\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision (macro): {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall (macro): {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-score (macro): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test, y_pred_probs):.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# ==== Confusion Matrix ====\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=[0,1,2], yticklabels=[0,1,2])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ==== Feature Importance ====\n",
    "importance = model.feature_importances_\n",
    "feature_names = X_model.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d478bc2b905af2a",
   "metadata": {},
   "source": [
    "## Multiclass Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4feba99f6d862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T16:11:06.445141Z",
     "start_time": "2025-05-18T15:54:26.844629Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, cohen_kappa_score, log_loss,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== 2. SPLIT TRAIN/TEST ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ==== 3. SCALING ====\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ==== 4. SMOTE RESAMPLING ====\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ==== 5. CUSTOM DATASET ====\n",
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values if isinstance(y, pd.Series) else y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = DiabetesDataset(X_resampled, y_resampled)\n",
    "test_dataset = DiabetesDataset(X_test_scaled, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ==== 6. MODEL DEFINITION ====\n",
    "class DiabetesModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ==== 7. FOCAL LOSS ====\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logpt = -self.ce(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "        return -((1 - pt) ** self.gamma) * logpt\n",
    "\n",
    "# ==== 8. MODEL SETUP ====\n",
    "model = DiabetesModel(X.shape[1])\n",
    "\n",
    "# Compute class weights based on inverse frequency (from resampled training set)\n",
    "class_counts = pd.Series(y_resampled).value_counts().sort_index()\n",
    "weights = 1. / torch.tensor(class_counts.values, dtype=torch.float)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "criterion = FocalLoss(gamma=1.5, weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 30\n",
    "\n",
    "# ==== 9. TRAINING LOOP ====\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "# ==== 10. EVALUATION ====\n",
    "model.eval()\n",
    "y_true, y_pred, y_probs = [], [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        y_true.extend(targets.tolist())\n",
    "        y_pred.extend(preds.tolist())\n",
    "        y_probs.extend(probs.tolist())\n",
    "\n",
    "# ==== 11. METRICS ====\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(f\"Accuracy:          {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision (macro): {precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Precision (weighted): {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall (macro):    {recall_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Recall (weighted): {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-score (macro):  {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_true, y_probs):.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# ==== 12. CONFUSION MATRIX ====\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6606558ee5f1f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
