{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "51cbaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5dfca5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Progress bar from https://stackoverflow.com/questions/3002085/how-to-print-out-status-bar-and-percentage/70586588#70586588\n",
    "def percent_complete(step, total_steps, bar_width=60, title=\"\", print_perc=True):\n",
    "    import sys\n",
    "\n",
    "    # UTF-8 left blocks: 1, 1/8, 1/4, 3/8, 1/2, 5/8, 3/4, 7/8\n",
    "    utf_8s = [\"█\", \"▏\", \"▎\", \"▍\", \"▌\", \"▋\", \"▊\", \"█\"]\n",
    "    perc = 100 * float(step) / float(total_steps)\n",
    "    max_ticks = bar_width * 8\n",
    "    num_ticks = int(round(perc / 100 * max_ticks))\n",
    "    full_ticks = num_ticks / 8      # Number of full blocks\n",
    "    part_ticks = 0      # Size of partial block (array index)\n",
    "    \n",
    "    disp = bar = \"\"                 # Blank out variables\n",
    "    bar += utf_8s[0] * int(full_ticks)  # Add full blocks into Progress Bar\n",
    "    \n",
    "    # If part_ticks is zero, then no partial block, else append part char\n",
    "    if part_ticks > 0:\n",
    "        bar += utf_8s[part_ticks]\n",
    "    \n",
    "    # Pad Progress Bar with fill character\n",
    "    bar += \"▒\" * int((max_ticks/8 - float(num_ticks)/8.0))\n",
    "    \n",
    "    if len(title) > 0:\n",
    "        disp = title + \": \"         # Optional title to progress display\n",
    "    \n",
    "    # Print progress bar in green: https://stackoverflow.com/a/21786287/6929343\n",
    "    disp += \"\\x1b[0;32m\"            # Color Green\n",
    "    disp += bar                     # Progress bar to progress display\n",
    "    disp += \"\\x1b[0m\"               # Color Reset\n",
    "    if print_perc:\n",
    "        # If requested, append percentage complete to progress display\n",
    "        if perc > 100.0:\n",
    "            perc = 100.0            # Fix \"100.04 %\" rounding error\n",
    "        disp += \" {:6.2f}\".format(perc) + \" %\"\n",
    "    \n",
    "    # Output to terminal repetitively over the same line using '\\r'.\n",
    "    sys.stdout.write(\"\\r\" + disp)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcd526",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dcbdea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"./dataset.csv\")\n",
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319cfe6",
   "metadata": {},
   "source": [
    "Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dd08420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Diabetes_012'], axis=1)\n",
    "y=data['Diabetes_012']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec485894",
   "metadata": {},
   "source": [
    "Let's try backward stepwise elimination (with multinominal logistische regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "868b82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'PhysActivity' with p = 0.7308\n",
      "Dropping 'DiffWalk' with p = 0.5998\n",
      "Dropping 'Smoker' with p = 0.5562\n",
      "Dropping 'HeartDiseaseorAttack' with p = 0.5250\n",
      "Dropping 'Fruits' with p = 0.4939\n",
      "Dropping 'AnyHealthcare' with p = 0.2242\n",
      "Dropping 'NoDocbcCost' with p = 0.1240\n",
      "Dropping 'Veggies' with p = 0.1182\n",
      "Dropping 'Stroke' with p = 0.0915\n",
      "Selected features: ['const', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'Sex', 'Age', 'Education', 'Income']\n"
     ]
    }
   ],
   "source": [
    "#Add constant for intercept\n",
    "def multinomial(X): \n",
    "    X = sm.add_constant(X)\n",
    "    cols = list(X.columns)\n",
    "    pmax = 1\n",
    "\n",
    "    while len(cols) > 0:\n",
    "        # Inside your while loop:\n",
    "        model = sm.MNLogit(y, X[cols]).fit(disp=0)\n",
    "\n",
    "        # Take max p-value per feature across classes\n",
    "        p_values = model.pvalues\n",
    "        p_values_max = p_values.max(axis=1)\n",
    "        pmax = p_values_max.max()\n",
    "        feature_with_p_max = p_values_max.idxmax()\n",
    "\n",
    "        # Backward elimination step\n",
    "        if pmax > 0.05:\n",
    "            print(f\"Dropping '{feature_with_p_max}' with p = {pmax:.4f}\")\n",
    "            cols.remove(feature_with_p_max)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Selected features: {cols}\")\n",
    "    return cols\n",
    "\n",
    "X_BSE_list = multinomial(X)\n",
    "X_BSE_list.remove('const')\n",
    "X_postBSE = X[X_BSE_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a761bc",
   "metadata": {},
   "source": [
    "Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3cacc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset into features and target variables\n",
    "def splitdataset(X, y):\n",
    "\n",
    "    # Splitting the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25386ce",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c28f26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate results\n",
    "def Evaluation(y_test, y_pred, y_pred_proba=None):\n",
    "\n",
    "    print(\"Accuracy:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", sklearn.metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", sklearn.metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1 Score:\", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "    if(y_pred_proba):\n",
    "        print(\"Log Loss:\", sklearn.metrics.log_loss(y_test, y_pred_proba, labels=[0, 1, 2]))\n",
    "    print(\"Cohen Kappa Score:\", sklearn.metrics.cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "    # Classification report per classe\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ea847",
   "metadata": {},
   "source": [
    "Hyper Parameter tuning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Variating_DecisionTreeClassifier(Xtrain, ytrain, Xtest, ytest, balanced_data=False):\n",
    "    \n",
    "    class_weight = None if balanced_data else \"balanced\"\n",
    "\n",
    "    criterions = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    maxDepth = [2,3,4,8,None] #added values around best found value 4\n",
    "    min_samples_leaf = [1, 10, 100, 1000, 10000]\n",
    "    \n",
    "\n",
    "    maxf1 = 0\n",
    "    parameters = \"\"\n",
    "\n",
    "    totalSteps = len(criterions) * len(maxDepth) * len(min_samples_leaf)\n",
    "    step = 0\n",
    "    print(\"Running Hyperparameter Search:\")\n",
    "    for criterion in criterions:\n",
    "        for d in maxDepth:\n",
    "            for m in min_samples_leaf:\n",
    "                #print(\"========= Class weigth:\" + str(cl) + \" Method: \" + criterion + \", maxDepth: \" + str(d) + \" ========\")\n",
    "                dtree = DecisionTreeClassifier(criterion=criterion, min_samples_leaf=m, max_depth=d, class_weight=class_weight, random_state=42)\n",
    "                dtree.fit(Xtrain, ytrain)\n",
    "                yPred = dtree.predict(Xtest)\n",
    "                if(sklearn.metrics.f1_score(ytest, yPred, average='macro') > maxf1):\n",
    "                    maxf1 = sklearn.metrics.f1_score(ytest, yPred, average='macro')\n",
    "                    parameters = \"Criterion: \" + criterion + \", depth: \" + str(d) + \", min_samples_leaf: \" + str(m) + \", class_weight: \" + str(class_weight)\n",
    "                    Best_Y_predicted = yPred\n",
    "                #print(\"F1 Score:\", sklearn.metrics.f1_score(y_test, y_predicted, average='macro'))\n",
    "                step += 1\n",
    "                percent_complete(step, totalSteps)\n",
    "\n",
    "    print(\"\\nComplete!\")\n",
    "    print(\"Best f1 (macro) score: \" + str(maxf1) + \" with parameter \" + parameters)\n",
    "\n",
    "    return Best_Y_predicted, maxf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc143f",
   "metadata": {},
   "source": [
    "Testing on whole Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221da0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Baseline: ==\n",
      "f1 (macro) score: 0.4025980576684079\n",
      "\n",
      "== Tuned Hyperparameters: ==\n",
      "Running Hyperparameter Search:\n",
      "\u001b[0;32m████████████████████████████████████████████████████████████\u001b[0m 100.00 %\n",
      "Complete!\n",
      "Best f1 (macro) score: 0.4121881615946991 with parameter Criterion: gini, depth: 3, min_samples_leaf: 1, class_weight: balanced\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "predictions = {}\n",
    "\n",
    "print(\"== Baseline: ==\")\n",
    "# testing first on the whole data set with default parameters as a baseline\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = dtree.predict(X_test)\n",
    "predictions[\"Baseline\"] = y_predicted\n",
    "scores[\"Baseline\"] = sklearn.metrics.f1_score(y_test, y_predicted, average='macro')\n",
    "\n",
    "print(\"f1 (macro) score: \" + str(scores[\"Baseline\"]))\n",
    "#Evaluation(y_test, y_predicted)\n",
    "\n",
    "print(\"\\n== Tuned Hyperparameters: ==\")\n",
    "# testing on the hole data set with hyperparameter tuning\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "result = Variating_DecisionTreeClassifier(X_train, y_train, X_test, y_test, balanced_data=False)\n",
    "predictions[\"Whole Dataset Tuned\"], scores[\"Whole Dataset Tuned\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17ab5f",
   "metadata": {},
   "source": [
    "with backward stepwise elimination and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b58225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Search:\n",
      "\u001b[0;32m████████████████████████████████████████████████████████████\u001b[0m 100.00 %\n",
      "Complete!\n",
      "Best f1 (macro) score: 0.4121881615946991 with parameter Criterion: gini, depth: 3, min_samples_leaf: 1, class_weight: balanced\n"
     ]
    }
   ],
   "source": [
    "# split reduced data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X_postBSE,y)\n",
    "predictions[\"BSE Tuned\"], scores[\"BSE Tuned\"] = Variating_DecisionTreeClassifier(X_train, y_train, X_test, y_test, balanced_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76665f5",
   "metadata": {},
   "source": [
    "Using SMOTE and hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split hole data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "sm = SMOTE(random_state=42) #better results with 40 than 42\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "32257f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Search:\n",
      "\u001b[0;32m████████████████████████████████████████████████████████████\u001b[0m 100.00 %\n",
      "Complete!\n",
      "Best f1 (macro) score: 0.3935187543666368 with parameter Criterion: entropy, depth: 8, min_samples_leaf: 1000, class_weight: None\n"
     ]
    }
   ],
   "source": [
    "predictions[\"SMOTE Tuned\"], scores[\"SMOTE Tuned\"] = Variating_DecisionTreeClassifier(X_train, y_train, X_test, y_test, balanced_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21917947",
   "metadata": {},
   "source": [
    "Using random oversampling and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "36d5b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: Counter({0: 170962, 2: 28277, 1: 3705})\n",
      "Resampled dataset: Counter({0: 170962, 2: 170962, 1: 170962})\n"
     ]
    }
   ],
   "source": [
    "# split hole data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "# Check class distribution before oversampling\n",
    "print(\"Before oversampling:\", Counter(y_train))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42) #better results with 42 than 40\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled dataset:\", Counter(y_resampled_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "28e2ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Search:\n",
      "\u001b[0;32m████████████████████████████████████████████████████████████\u001b[0m 100.00 %\n",
      "Complete!\n",
      "Best f1 (macro) score: 0.4121881615946991 with parameter Criterion: gini, depth: 3, min_samples_leaf: 1, class_weight: None\n"
     ]
    }
   ],
   "source": [
    "predictions[\"Oversampling Tuned\"], scores[\"Oversampling Tuned\"] = Variating_DecisionTreeClassifier(X_resampled_ros, y_resampled_ros, X_test, y_test, balanced_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610a311",
   "metadata": {},
   "source": [
    "Backward stepwise elimination, random oversampling and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2f5bd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: Counter({0: 170962, 2: 28277, 1: 3705})\n",
      "Resampled dataset: Counter({0: 170962, 2: 170962, 1: 170962})\n"
     ]
    }
   ],
   "source": [
    "# split reduced data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X_postBSE,y)\n",
    "\n",
    "# Check class distribution before oversampling\n",
    "print(\"Before oversampling:\", Counter(y_train))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_BSE_ros, y_resampled_BSE_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled dataset:\", Counter(y_resampled_BSE_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e7c88ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Search:\n",
      "\u001b[0;32m████████████████████████████████████████████████████████████\u001b[0m 100.00 %\n",
      "Complete!\n",
      "Best f1 (macro) score: 0.4121881615946991 with parameter Criterion: gini, depth: 3, min_samples_leaf: 1, class_weight: None\n"
     ]
    }
   ],
   "source": [
    "predictions[\"BSE Oversampled Tuned\"], scores[\"BSE Oversampled Tuned\"] = Variating_DecisionTreeClassifier(X_resampled_BSE_ros, y_resampled_BSE_ros, X_test, y_test, balanced_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60ef2a",
   "metadata": {},
   "source": [
    "Detailed results for the best F1 score found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9e13519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Method: Whole Dataset Tuned\n",
      "Best Score: 0.4121881615946991\n",
      "\n",
      "== Evaluation of best performed method: == \n",
      "\n",
      "Accuracy: 0.6504848628193\n",
      "Precision: 0.4249002538368072\n",
      "Recall: 0.4843635863557357\n",
      "F1 Score: 0.4121881615946991\n",
      "Cohen Kappa Score: 0.2296872768656263\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.6685    0.7802     42741\n",
      "           1     0.0255    0.1814    0.0447       926\n",
      "           2     0.3124    0.6032    0.4117      7069\n",
      "\n",
      "    accuracy                         0.6505     50736\n",
      "   macro avg     0.4249    0.4844    0.4122     50736\n",
      "weighted avg     0.8331    0.6505    0.7154     50736\n",
      "\n",
      "Method: Baseline, Score: 0.4025980576684079\n",
      "Method: Whole Dataset Tuned, Score: 0.4121881615946991\n",
      "Method: BSE Tuned, Score: 0.4121881615946991\n",
      "Method: SMOTE Tuned, Score: 0.3935187543666368\n",
      "Method: Oversampling Tuned, Score: 0.4121881615946991\n",
      "Method: BSE Oversampled Tuned, Score: 0.4121881615946991\n"
     ]
    }
   ],
   "source": [
    "BestMethod = max(scores, key=scores.get)\n",
    "\n",
    "print(\"Best Method: \" + BestMethod)\n",
    "print(\"Best Score: \" + str(scores[BestMethod]))\n",
    "\n",
    "Best_Y_predicted = predictions[BestMethod]\n",
    "\n",
    "print(\"\\n== Evaluation of best performed method: == \\n\")\n",
    "Evaluation(y_test, Best_Y_predicted)\n",
    "# Evaluation(y_test, Best_Y_predicted_postBSE)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, Best_Y_predicted, labels=[0, 1, 2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig(\"Output/Confusion_Matrix_Decision_Tree.png\")\n",
    "plt.close()\n",
    "\n",
    "for k,v in scores.items():\n",
    "    print(\"Method: \" + k + \", Score: \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8506271",
   "metadata": {},
   "source": [
    "Plot the decision tree of best F1 macro score\n",
    "###### Method: Whole Dataset Tuned, Score: 0.4121881615946991 as others exept Baseline and SMOTE performed identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1cd87d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (macro) Score: 0.4121881615946991\n"
     ]
    }
   ],
   "source": [
    "# split hole data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, min_samples_leaf=1, class_weight=\"balanced\", random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "#ploting desicion tree\n",
    "plt.figure(figsize=(80, 40))\n",
    "sklearn.tree.plot_tree(dtree, filled=True, feature_names=X.columns, proportion=True)\n",
    "plt.savefig(\"output/high_res_tree.png\", dpi=500, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#testing if same F1 macro score was found\n",
    "y_predicted = dtree.predict(X_test)\n",
    "print(\"F1 (macro) Score:\", sklearn.metrics.f1_score(y_test, y_predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea6cb6",
   "metadata": {},
   "source": [
    "Testing best model found for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e83f16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.653914380321665\n",
      "Precision: 0.42878848339554637\n",
      "Recall: 0.49509318997482143\n",
      "F1 Score: 0.4171939247991017\n",
      "Cohen Kappa Score: 0.23679232463983046\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9388    0.6706    0.7824    170962\n",
      "           1     0.0282    0.2027    0.0495      3705\n",
      "           2     0.3194    0.6119    0.4197     28277\n",
      "\n",
      "    accuracy                         0.6539    202944\n",
      "   macro avg     0.4288    0.4951    0.4172    202944\n",
      "weighted avg     0.8359    0.6539    0.7185    202944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split hole data set\n",
    "X_train, X_test, y_train, y_test = splitdataset(X,y)\n",
    "\n",
    "# using the training set for the evaluation\n",
    "dtree = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, min_samples_leaf=1, class_weight=\"balanced\", random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "Evaluation(y_train, dtree.predict(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
